% thesisbackground.tex

% Background and Related Work
\chapter{Background and Related Work}
\label{cha:backgroundandrelatedwork}
System simulators are abundant and exist in corporate~\dvtcmdcitebib{magazines:bohrer:2004}, academic~\dvtcmdcitebib{journals:rosenblum:1995}, and open-source variations~\dvtcmdciteref{magazines:bartholomew:2006}.
Such platforms, like \dvttermsimics , have been used for a variety of purposes including, but not limited to, thermal control strategies in multicores~\dvtcmdcitebib{inproceedings:bartolini:2010}, networking timing analysis~\dvtcmdcitebib{journals:ortiz:2009}, web server performance evaluation~\dvtcmdcitebib{journals:villa:2005}, and to simulate costly hardware financially unfeasible to researchers~\dvtcmdcitebib{journals:alameldeen:2003}.
Furthermore, such simulators may be used to port \dvttermos s to new processors~\dvtcmdciteref{technicaldocs:netbsd:2014}.

For the purposes of graphics acceleration, strategies, methodologies and procedures are numerous; several of which are expanded upon in chapter \ref{cha:proposedsolutionandimplementation}.
Based off these core strategies, such as device modeling, various passthrough technologies, and paravirtualization, there have been numerous attempts at effective \dvttermgpu\ virtualization; many of which require modification of both \dvttermtarget - and \dvttermhost\ systems, such as the development of specialized passthrough drivers~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}.
One such instance is presented by Hansen in his work on the Blink display system~\dvtcmdcitebib{inproceedings:hansen:2007}.

Neither are the concepts of advanced simulatory features new to \dvttermgpu\ virtualization, as there have are multiple attempts to implement the \dvttermcheckpointrestart -model in a \dvttermgpu\ context, such as the work done by Guo et al. on the CUDA framework~\dvtcmdcitebib{inproceedings:guo:2013}.
Another solution which also supports the \dvttermcheckpointrestart -scheme is VMGL, as presented by Lagar-Cavilla et al., which by the means of paravirtualization accelerated the \dvttermopengl\ $1.5$ framework~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}.
The groundwork produced by Lagar-Cavilla et al. showcased the potential for paravirtualized graphics, as the VMGL framework, for a certain set of benchmarks, attained improvements of roughly two orders of magnitude - in relation to software rasterization performed for the sake of said experiment.

Current promising projects surrounding \dvttermgpu\ virtualization include the Virgil3D-project~\dvtcmdciteref{technicaldocs:qemudevel:2014}.
As described at the project homepage\footnote{\href{http://virgil3d.github.io/}{www.virgil3d.github.io}}, the project strives to create a virtual \dvttermgpu\ which may subsequently utilize \dvttermhost\ hardware to accelerate 3D rendering.
The project is currently being maintained, again according to the projects GitHub homepage, by Red Hat's Dave Airlie.

Other related works include modeling \dvttermgpu\ devices in the \dvttermqemu\ full-system simulator with software \dvttermopengles\ rasterization support, as presented by Shen et al.~\dvtcmdcitebib{inproceedings:shen:2010}.

As of the time of writing, graphics virtualization is no longer limited to the academic community but is also existent in the industry as big virtualization players incorporate various graphics acceleration solutions in their products.
One such example is \dvttermvmware ~\dvtcmdciteref{technicaldocs:vmware:2014}.

Pursuant to the aim and objectives specified in chapter \ref{cha:aimsandobjectives}, this thesis pertain to the technologies and concepts described in this chapter.

% TODO:
% Insert section on OpenGL ES
% Insert section on GPU Architecture

% Graphics Virtualization
\section{Graphics Virtualization}
\label{sec:backgroundandrelatedwork_graphicsvirtualization}
There are a number of ways of virtualizing \dvttermgpu s in system simulators, a few of which accommodate for hardware acceleration of \dvttermgpu\ kernels.
When faced with tackling the issue of \dvttermgpu\ virtualization, there are equally many variables to consider as there are options; the first of which is the purpose of said virtualization.
The \dvttermsimics\ architectural simulator is by all means a full-system simulator; meaning, as portrayed in section \ref{cha:simics}, that it may run real-software stacks without modification.
However, \dvttermsimics\ is intended to feature a low level of timing fidelity for the purposes of high performance, and is - as such - not a cycle-accurate simulator.
In this way, and in line with the considerations for \dvttermgpu\ virtualization, one must analyze and balance the purposes of simulation since there is not always a general winning-case.
As such, methodologies with varying levels of implementational accuracy present themselves - from slow low-level instruction set modeling to fast high level paravirtualization of an assortment of graphics frameworks.
Said methods are presented in paragraphs \dvtcmdrefname{par:backgroundandrelatedwork_graphicsvirtualization_gpumodeling}, \dvtcmdrefname{par:backgroundandrelatedwork_graphicsvirtualization_pcipassthrough}, \dvtcmdrefname{par:backgroundandrelatedwork_graphicsvirtualization_softmodeling}, and \dvtcmdrefname{par:backgroundandrelatedwork_graphicsvirtualization_paravirtualization}.

% TODO: Insert figure visualizing virtualization methodologies (see https://github.com/CaterHatterPillar/dv2524/issues/161).
%\missingfigure[figwidth=6cm]{Visualization of GPU virtualization methodologies.}

% GPU Modeling
\paragraph{GPU Modeling}
\label{par:backgroundandrelatedwork_graphicsvirtualization_gpumodeling}
One may consider developing a full-fletched \dvttermgpu\ model; that is, virtualizing the \dvttermgpu\ \dvttermisa .
This methodology may be appropriate for the purposes of low-level development close to \dvttermgpu\ hardware.
For example, one might imagine the scenario of driver development for next-generation \dvttermgpu s.

However, the development of \dvttermgpu\ models, similar to that of common architectural model development for the \dvttermsimics\ full-system simulator, incurs a number of flaws.
The first of these flaws, due to \dvttermgpu\ hardware - still - often being poorly documented~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}, on the contrary to \dvttermcpu\ architectures, driving estimated development costs to unsustainable levels.
Furthermore, such modeling of massively parallelized \dvttermgpu\ technology on \dvttermcpu s induce high costs rendering the methodology less preferable for development requiring high application speed.

% PCI Passthrough
\paragraph{PCI Passthrough}
\label{par:backgroundandrelatedwork_graphicsvirtualization_pcipassthrough}
Furthermore, one ought to examine the benefits of \dvttermpcipassthrough ; allowing virtual systems first-hand - exclusive - access to \dvttermhost\ machine devices~\dvtcmdciteref{web:jones:2009}.
The direct contact with \dvttermhost\ system devices accommodated by methodologies such as \dvttermpcipassthrough\ enable hardware accelerated graphics.

The methodology suffers from several disadvantages, such as implementations being limited to a small number of \dvttermlinux\ platforms.
Additionally, the solution requires dedicated hardware, causing the \dvttermhost\ system to lose all access to said devices during the course of simulation.
In terms of \dvttermgpu\ virtualization, this would induce the necessity of the \dvttermhost\ machine featuring multiple graphics cards.
The tight coupling induced by direct contact with \dvttermhost\ hardware also requires the simulation \dvttermtarget\ to utilize the same device drivers as the \dvttermhost\ system, rendering the methodology unflexible in terms of \dvttermgpu\ virtualization diversity.
In line with a paravirtualized approach, \dvttermpcipassthrough\ also requires modification of the \dvttermtarget\ system - in addition to configuration of the simulation \dvttermhost .

% Soft Modeling
\paragraph{Soft Modeling}
\label{par:backgroundandrelatedwork_graphicsvirtualization_softmodeling}
As an alternative to precise modeling of \dvttermgpu\ technologies, one might analyze the feasibility of high-speed software rasterization.
Albeit not up to hardware accelerated speeds, some results indicate an increased feasibility of high-speed software rasterization in modern graphics frameworks (see ~\dvtcmdciteref{papers:nilsson:2013}), where traditional software rasterization is accelerated using thread pooling optimizations and \dvttermsimd\ technologies~\dvtcmdciteref{web:microsoft:2013:warp}; all for the purposes of optimizing execution for \dvttermcpu -, rather than \dvttermgpu -, execution.
As such, one may avoid some of the overhead induced by simulating \dvttermgpu\ workload on \dvttermcpu s, which is traditionally not fit for purpose.
One might speculate that using such technologies in collaboration with \dvttermhost\ native execution acceleration might bring software rasterization up to competitive speeds fit for some simulatory development purposes, replacing the need for more sophisticated virtualization techniques.

% Paravirtualization
\paragraph{Paravirtualization}
\label{par:backgroundandrelatedwork_graphicsvirtualization_paravirtualization}
Finally, there is the option of virtualization by paravirtualization.
Paravirtualization incurs the benefits of \dvttermhost\ hardware acceleration of some framework graphics library, and is implemented at a relatively high abstraction level (see figure \ref{fig:overview}).
Inherent from its higher abstraction, paravirtualization may be relatively cost-effective to implement - in comparison to alternatives such as \dvtcmdrefname{par:backgroundandrelatedwork_graphicsvirtualization_gpumodeling}.
Additionally, virtualizing at the graphics library software level circumvents the need for users to re-link or modify the application they wish accelerated.
Furthermore, the serialization of framework invocations by the means of fast communications channels (see section \ref{sec:proposedsolutionandimplementation_simicspipe}) may accommodate for significant performance improvements when compared to that of networking solutions (see ~\dvtcmdciteref{dissertation:nilsson:2014}).

However, despite the possibility for significant performance improvements (see chapter \ref{cha:results}), graphics virtualization by the means of paravirtualization is not without it's inherent flaws.
In particular, a paravirtualized graphics library may be expensive to maintain as frameworks evolve and specifications change.
Additionally, the means of paravirtualization requires the target system to be modified; albeit not necessarily being a substantial flaw as such a paravirtualized framework may still accelerate unmodified \dvttermtarget\ applications utilizing said library.
In this way, paravirtualization may be considered to be a decent leveling of the benefits and drawbacks of the various virtualization methodologies presented in this section.

% TODO:
% Expand upon why paravirtualization is a sensible levelling.

% QEMU
\section{QEMU}
\label{sec:backgroundandrelatedwork_qemu}
\index{QEMU}
\index{Android Emulator}
\index{Reference Solution}
\index{Reference Implementation}
\dvttermqemu \footnote{'Quick~Emulator'.} is an open-source virtual platform described as a full system emulator~\dvtcmdcitebib[p.~1]{inproceedings:bellard:2005} and a high-speed functional simulator~\dvtcmdcitebib[p.~1]{inproceedings:shen:2010} (see ~\dvtcmdciteref[p.~69]{magazines:bartholomew:2006} for an overview of \dvttermqemu ).
Its virtual platform supports simulation of several common system architectures and hardware devices and can, like \dvttermsimics , save and restore the state of a simulation~\dvtcmdcitebib[p.~1]{inproceedings:bellard:2005}.

As such, \dvttermqemu\ may, like \dvttermsimics , run unmodified \dvttermtarget\ software such as \dvttermos s, drivers, and other applications.
The platform is widely used in academia, and is the subject of several articles and reports cited throughout this document such as the graphics acceleration described by Lagar-Cavilla et al.~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}, and the work by Guo et al.~\dvtcmdcitebib{inproceedings:guo:2013}.
Additionally, \dvttermqemu\ powers the \dvttermandroidemulator , which helps mobile developers bring about software for the \dvttermandroid\ \dvttermos .

The \dvttermandroidemulator\ is described as a virtual mobile device emulator~\dvtcmdciteref{web:google:2013:usingtheemulator}.
Included in the \dvttermandroidsdk , it supports virtualization of an assortment of mobile hardware configurations.

In the presence of the \dvttermandroid\ \dvtcmdnum{4.0.3} release, the \dvttermandroidsdk\ was updated to make use of hardware-assisted \dvttermxeightysix\ virtualization; significantly increasing the performance of \dvttermcpu -bound workloads~\dvtcmdciteref{web:ducrohet:2012:afasteremulator}.
In addition to this, \dvttermgoogle\ implemented \dvttermopengles\ \dvtcmdnum{1.1} and \dvtcmdnum{2.0} hardware acceleration; offering a substantial performance boost to developers utilizing the \dvttermopengles\ frameworks~\dvtcmdciteref{web:ducrohet:2012:afasteremulator}.
\dvttermgoogle 's solution~\dvtcmdciteref{technicaldocs:google:2014}, consists of a paravirtualized implementation which circumvents the simulated system by forwarding its \dvttermopengles\ invocations to the \dvttermhost\ system by using networking sockets or directly via the simulator program.
Note, however, that there is no software rasterized solution for running \dvttermopenglestwopointo\ in the \dvttermandroidemulator .

As of \dvttermandroid\ \dvtcmdnum{4.4}, the \dvttermandroidemulator\ uses \dvttermqemu\ to simulate \dvttermarm\ and \dvttermxeightysix \footnote{In coagency with images compiled by \dvttermintel , the \dvttermandroidemulator\ may be used to run the \dvttermandroid\ \dvttermos\ on \dvttermxeightysix\ simulated hardware (see section \ref{sec:experimentalmethodology_platformconfiguration}).} devices aiding those wishing to develop software for mobile units.
The \dvttermandroidemulator\ implementation is referred to as the \dvttermreferencesolution\ throughout this document.

% Magic Instructions
\section{Magic Instructions}
\label{sec:backgroundandrelatedwork_magicinstructions}
\index{Magic Instruction}
Sometimes during system simulation, there may be reasons as to why one would like to escape the simulation and resume execution in the real world.
Such a scenario would be a debugging breakpoint, to share data in-between \dvttermtarget\ and \dvttermhost\ systems, or for any reason modify the simulation state.
There are a number of ways to communicate with the outside world (including the \dvttermhost\ machine) from within the simulation, such as by networking means or specially devised kernel drivers, but few are as instant as the - arguably - legitimately coined '\dvttermmagicinstruction '.

The \dvttermmagicinstruction\ is a concept used to denote a \dvtcmdcodeinline{nop}-type instruction, meaning an instruction that would have no effect if run on the \dvttermtarget\ architecture (such as \dvtcmdcodeinline{xchg ebx, ebx}\footnote{'Swap contents in registers \dvtcmdcodeinline{ebx} and \dvtcmdcodeinline{ebx}'.} on the \dvttermxeightysix -architecture), which - when executed on the simulated hardware in a virtual platform - invokes a certain callback-method~\dvtcmdcitebib[p.~32]{publications:leupers:2010}.
An advantage of this methodology is an often negligible invocation cost, as the context switch is often instant from the perspective of the \dvttermtarget\ system~\dvtcmdcitebib[p.~131]{journals:rechistov:2013}.
Furthermore, and a greatly desirable attribute, \dvttermmagicinstruction s require no modification of the \dvttermtarget\ system.
Another advantage of the \dvttermmagicinstruction\ paradigm is that the system invoking such an instruction may, without complications, run outside of a simulation - as this would simply result in regular \dvtcmdcodeinline{nop}-behavior.

In effect, implementation of \dvttermmagicinstruction s requires replacing one- or more instructions in the \dvttermtarget\ instruction set; thereby making the \dvttermmagicinstruction\ platform-dependent.
However, the solution is often designed to only respond to \dvttermmagicinstruction s wherein a certain magic number, sometimes called a 'leaf number'~\dvtcmdcitebib[p.~131]{journals:rechistov:2013}, is present in an arbitrary processor register.

% Virtual Time
\section{Virtual Time}
\label{sec:backgroundandrelatedwork_virtualtime}
\index{Virtual Time}
In terms of system simulation, time often becomes abstract; since it is not necessarily the same for an observer outside of the simulation as that of an observer from the inside.
The variance in virtual time, as compared to that of real-world time, is called 'simulation slowdown' and may reach orders of magnitude faster than that of real-world time, or likewise orders of magnitude slower.

The concepts of real-world and virtual time are particularly important when considering performance measurements.
When attempting to establish some sort of measurement in a full-system simulator, such as \dvttermsimics , one must contemplate what type of time is relevant to the study being performed.
For graphics acceleration of real-time applications, it is likely that the real-world wall clock is the primary point of reference (see section \ref{sec:experimentalmethodology_platformprofiling} for an elaboration on how time measurement is performed for the sake of this study).
However, there are cases in which virtual time is more relevant to analyze.

%Explain the concepts of virtual time. Expand upon how timing was achieved in Simics and QEMU, respectively.
%http://stackoverflow.com/questions/5774612/is-the-emulator-clock-synced-to-the-real-system-clock
%https://wiki.diebin.at/Under_the_hood_of_Android_Emulator_(appcert)#vl-android.c.2Finit_clocks.28.29:
%http://gamasutra.com/view/feature/171774/getting_high_precision_timing_on_.php?print=1
